{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-detail",
   "metadata": {},
   "source": [
    "# Going Deeper(NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-asian",
   "metadata": {},
   "source": [
    "# 6. 번역가는 대화에도 능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-assessment",
   "metadata": {},
   "source": [
    "# 멋진 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-helen",
   "metadata": {},
   "source": [
    "* Writer :송영석\n",
    "* Date : 2022.01.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-basin",
   "metadata": {},
   "source": [
    "## 목차\n",
    "    \n",
    "    Step 1. 서론  \n",
    "\n",
    "    Step 2. 데이터 분석 \n",
    "\n",
    "    Step 3. 데이터 전처리\n",
    "\n",
    "    Step 4. 데이터 토큰화\n",
    "        - Lexical Substitution\n",
    "        \n",
    "    Step 6. Transformer 모델 생성\n",
    "        - 토큰추가\n",
    "        - 벡터화\n",
    "        \n",
    "    Step 7. 모델 학습\n",
    "        - Transformer 사용\n",
    "   \n",
    "     Step 8. 모델 평가\n",
    "        - BLEU Score 사용  \n",
    "     \n",
    "     Step 9. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-target",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 초록\n",
    "***\n",
    "<span style=\"font-size:11pt; line-height:1.8;\">\n",
    "    &nbsp; &nbsp; Transformer 한국어 챗봇 모델을 생성하고 BLEU를 이용하여 모델을 평가하였다. 송영숙(2018)이 제시한 『Chatbot data for Korean v1』을 학습 데이터셋으로 사용 하였다. 데이터 분석 결과 총 레코드 수는 11,823개이며, 결측치 0개, 중복 데이터 73개가 존재하였다. 따라서, '중복 데이터 제거' ,'정규식을 이용한 문장 전처리', '형태소 기준 문장 분할'을 수행하여 총 11,750개의 데이터를 확보하고 테스트 데이터 100개, 학습 데이터 11,650개로 분할 하였다. 문장 길이와 토큰 사용 빈도를 분석하여, 질문 데이터의 경우 토큰이 15개 이하로 사용되고 대답 데이터의 경우에는 토큰이 18개 이하로 사용된 문장만을 추출하였다. 또한 토크나이저의 단어사전 크기는 5,872개로 설정하였다. 이후, 이미 학습된 Word2Vec을 이용하여 데이터 증강을 수행하였으며, 최종 29,951개의 학습 데이터를 확보 하였다. 모델 생성 시, 인코더와 디코더 레이어는 2층을 쌓았으며, 학습 데이터 수가 적기 때문에 벡터 사이즈와 피드포워드 레이어의 유닛 수를 128로 설정 하였다. 학습 옵티마이저는 Adam을 사용하며 배치 사이즈는 64로 설정하고 총 10회 학습 하였다. 「지루하다, 놀러가고 싶어.」, 「오늘 일찍 일어났더니 피곤하다.」 등의 총 4개의 문장을 입력한 결과, 「시간이 필요한가 봐요.」, 「아침 일이 많았나 봅니다.」 등의 문장을 출력하였다. 앞서 분할한 100개의 테스트 데이터에 대한 모델의 BLEU score는 0.419임을 확인하였다. 이는 '이해할 수 있는 양호한 문장'으로 Transformer 한국어 챗봇 모델의 성능은 양호한 수준이라 평가할 수 있다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-insight",
   "metadata": {},
   "source": [
    "#### _예제 진행에 앞서..._\n",
    "***\n",
    "+ 예제에서 사용하는 한국어 형태소 분석기 Mecab을 이용하기 위해 미리 설치 하여 줍니다.\n",
    "\n",
    "> `$ sudo apt-get install g++ openjdk-8-jdk` #jdk 설치\n",
    ">\n",
    "> `$ bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)` #curl을 이용한 Mecab 설치\n",
    ">\n",
    "> `$ pip install konlpy` #konlpy 설치\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-techno",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 예제에서 사용하는 데이터는 송영숙(2018)이 제시한 『Chatbot data for Korean v1』을 이용합니다. 데이터는 질문과 대답 그리고 질문의 평상, 긍정, 부정에 대한 0에서 2사이의 값으로 이루어져 있습니다. 예제에서는 질문(Question)과 대답(Answer) 데이터만을 이용합니다.  레코드 수는 총 11,823개이며 결측치는 0개, 중복 데이터 73개가 존재 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-phone",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 호출\n",
    "***\n",
    "+ 예제에 필요한 라이브러리를 호출 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   #정규식\n",
    "import random   #데이터 증강용 난수\n",
    "import numpy as np   #행렬 연산\n",
    "import pandas as pd   #데이터프레임\n",
    "import tensorflow as tf   #신경망\n",
    "import matplotlib.pyplot as plt   #데이터 시각화\n",
    "from tqdm.notebook import tqdm   #학습 과정 출력\n",
    "\n",
    "\n",
    "import gensim   #Word2Vec\n",
    "from konlpy.tag import Mecab   #형태소 분석\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu   #bleu 연산\n",
    "from nltk.translate.bleu_score import SmoothingFunction   #bleu 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-settlement",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터셋 불러오기\n",
    "***\n",
    "+ 질문(Q)과 대답(A) 그리고 일상(0), 부정(1), 긍정(2)의 도메인을 가지는 label로 구성되어 있으며 본 예제에서는 질문(Q)과 대답(A) 데이터만 이용합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>헤이진지 이제 딱 한달</td>\n",
       "      <td>후폭풍이 지나갔길 바랄게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11697</th>\n",
       "      <td>친구들이 짝녀를 별로라고 하네요.</td>\n",
       "      <td>무슨 이유에서 그랬을까요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>피자 막막 먹고 싶어.</td>\n",
       "      <td>배달 시키세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>불 날 뻔했어</td>\n",
       "      <td>조심하세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11707</th>\n",
       "      <td>친구의 남친 좋아하게 된 거 같아</td>\n",
       "      <td>사랑은 쟁취하는 거예요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Q                A\n",
       "8725         헤이진지 이제 딱 한달  후폭풍이 지나갔길 바랄게요.\n",
       "11697  친구들이 짝녀를 별로라고 하네요.   무슨 이유에서 그랬을까요.\n",
       "4928         피자 막막 먹고 싶어.         배달 시키세요.\n",
       "2172              불 날 뻔했어           조심하세요.\n",
       "11707  친구의 남친 좋아하게 된 거 같아    사랑은 쟁취하는 거예요."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./dataset/ChatbotData.csv\")\n",
    "dataset.drop((\"label\"), axis=\"columns\", inplace=True)\n",
    "\n",
    "display(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-ceramic",
   "metadata": {},
   "source": [
    "#### 학습 데이터 출처\n",
    "***\n",
    "+ YeongSook Song, Chatbot_data_for_Korean v1.0(2018), https://github.com/songys/Chatbot_data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-upset",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 레코드 수, 결측치, 중복 데이터 확인\n",
    "***\n",
    "+ 레코드 수는 총 11,823개 이며, 0개의 결측치, 73개의 중복 데이터가 존재합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaningful-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 184.9+ KB\n",
      "Dupliacted Data Num: 73\n"
     ]
    }
   ],
   "source": [
    "dataset.info()\n",
    "dup = dataset.duplicated()\n",
    "dup = dup.value_counts()[True]\n",
    "\n",
    "print(f\"Dupliacted Data Num: {dup:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-being",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 전처리는 '중복 데이터 제거', '정규식을 이용한 문장 전처리', 'Mecab을 이용한 형태소 기준 문장 분할' 순으로 진행 합니다. 중복 데이터 제거를 통해 총 11,750개의 데이터를 확보한 후, 숫자, 한글, 영어, 필요 특수기호를 제외한 문자는 제거하고 각 문자 간 공백을 추가 하여 줍니다. 그 후, Mecab을 이용하여 형태소를 기준으로 문장을 구분하여 주고 디코더 문장 즉, Answer 문장에는 &lt;sos>와 &lt;eos> 토큰을 추가하여 줍니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-deployment",
   "metadata": {},
   "source": [
    "#### 중복 데이터 제거\n",
    "***\n",
    "+ 중복 데이터를 제거하여 총 11,750개의 데이터를 획득합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electoral-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Num: 11,750\n"
     ]
    }
   ],
   "source": [
    "dataset.drop_duplicates(inplace=True)\n",
    "print(f\"Data Num: {len(dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-archive",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 정규식을 이용한 문장 전처리\n",
    "***\n",
    "+ 정규식을 이용하여 특수문자 제거 및 공백 추가 등의 작업을 수행 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "therapeutic-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>그런 사람인갑다 해야지</td>\n",
       "      <td>대인배시군요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>음 . 헤어졌는데 아직 잘 모르겠어</td>\n",
       "      <td>실감이 안날 수 있어요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>짝녀한테 여러 번 차였는데 사귈 수 있을까요 .</td>\n",
       "      <td>진심이 언젠간 통할지도 몰라요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3605</th>\n",
       "      <td>유기견 분양 받으려고</td>\n",
       "      <td>좋은 생각입니다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9028</th>\n",
       "      <td>교회 오빠한테 눈이 가</td>\n",
       "      <td>성경 공부는 안하고 연애 공부하나봅니다 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Q                        A\n",
       "327                  그런 사람인갑다 해야지                 대인배시군요 .\n",
       "7322          음 . 헤어졌는데 아직 잘 모르겠어           실감이 안날 수 있어요 .\n",
       "11551  짝녀한테 여러 번 차였는데 사귈 수 있을까요 .       진심이 언젠간 통할지도 몰라요 .\n",
       "3605                  유기견 분양 받으려고               좋은 생각입니다 .\n",
       "9028                 교회 오빠한테 눈이 가  성경 공부는 안하고 연애 공부하나봅니다 ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#전처리 함수===========================\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([0-9?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅎ가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "#End===================================\n",
    "\n",
    "\n",
    "dataset[\"Q\"] = dataset[\"Q\"].apply(preprocess_sentence)\n",
    "dataset[\"A\"] = dataset[\"A\"].apply(preprocess_sentence)\n",
    "\n",
    "display(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-monster",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mecab을 이용한 형태소 기준 문장 분할\n",
    "***\n",
    "+ Mecab을 이용하여 문장을 형태소 기준으로 분할 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modern-success",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>문 안 열림</td>\n",
       "      <td>힘껏 밀 어 보 세요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>마지막 이 겠 죠</td>\n",
       "      <td>마지막 이 아닐 지도 몰라요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>직구 로 사 야지</td>\n",
       "      <td>좋 은 거 사 나 봐요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>회복 되 는 게 하루하루 가 다른 거 같 아 ! !</td>\n",
       "      <td>회복력 이 좋 으시 군요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>나이 먹 고 짝사랑 하 는 내 가 한심 해 .</td>\n",
       "      <td>사랑 에 는 나이 가 상관 없 어요 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Q                      A\n",
       "1771                        문 안 열림          힘껏 밀 어 보 세요 .\n",
       "6234                     마지막 이 겠 죠      마지막 이 아닐 지도 몰라요 .\n",
       "4301                     직구 로 사 야지         좋 은 거 사 나 봐요 .\n",
       "8779  회복 되 는 게 하루하루 가 다른 거 같 아 ! !        회복력 이 좋 으시 군요 .\n",
       "9210     나이 먹 고 짝사랑 하 는 내 가 한심 해 .  사랑 에 는 나이 가 상관 없 어요 ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Mecab()\n",
    "\n",
    "dataset[\"Q\"] = dataset[\"Q\"].apply(lambda x: \" \".join(m.morphs(x)))\n",
    "dataset[\"A\"] = dataset[\"A\"].apply(lambda x: \" \".join(m.morphs(x)))\n",
    "\n",
    "display(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-district",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 디코더 문장 &lt;SOS>, &lt;EOS> 토큰 추가\n",
    "***\n",
    "+ 디코더에 입력할 데이터 문장 앞, 뒤에 &lt;SOS> 및 &lt;EOS> 토큰을 추가하여 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competent-challenge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>남자 친구 는 어디 서 만나</td>\n",
       "      <td>&lt;sos&gt; 원 하 는 사람 이 있 는 장소 에 가 보 세요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8618</th>\n",
       "      <td>헤어진지 1 년 .</td>\n",
       "      <td>&lt;sos&gt; 아직 도 힘들 지 않 았 으면 좋 겠 어요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11663</th>\n",
       "      <td>첫 사랑 을 추억 해</td>\n",
       "      <td>&lt;sos&gt; 첫 사랑 은 항상 추억 의 대상 이 죠 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>술 좀 그만 마셔야 지</td>\n",
       "      <td>&lt;sos&gt; 술 은 적당히 즐기 세요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10489</th>\n",
       "      <td>어떻게 여러 명 을 좋아할 수 있 어 ?</td>\n",
       "      <td>&lt;sos&gt; 저 도 이해 는 안 갑니다 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Q                                         A\n",
       "749           남자 친구 는 어디 서 만나  <sos> 원 하 는 사람 이 있 는 장소 에 가 보 세요 . <eos>\n",
       "8618               헤어진지 1 년 .     <sos> 아직 도 힘들 지 않 았 으면 좋 겠 어요 . <eos>\n",
       "11663             첫 사랑 을 추억 해       <sos> 첫 사랑 은 항상 추억 의 대상 이 죠 . <eos>\n",
       "2632             술 좀 그만 마셔야 지               <sos> 술 은 적당히 즐기 세요 . <eos>\n",
       "10489  어떻게 여러 명 을 좋아할 수 있 어 ?              <sos> 저 도 이해 는 안 갑니다 . <eos>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"A\"] = dataset[\"A\"].apply(lambda x: \"<sos> \" + x + \" <eos>\")\n",
    "\n",
    "display(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-recommendation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 데이터 토큰화\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 토큰화는 앞서, Mecab을 이용하여 형태소 기준으로 문장을 문할 하였기 때문에 이를 바로 토크나이저에 추가하여 사용 합니다. 문장의 길이와 단어사전 크기 설정을 위해, 분석을 진행하였습니다. 4분위에 해당하는 문장의 길이를 확인한 결과, 질문(Question) 데이터의 경우, 약 15개의 토큰으로 이루어져 있습니다. 대답(Answer) 데이터의 경우, 약 18개의 토큰으로 이루어져 있습니다. 총 토큰은 6,810개 이며, 4분위에 해당하는 토큰의 사용 빈도는 약 16회 입니다. 또한, 16회 이하로 사용된 토큰은 총 5,872개 입니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 이를 바탕으로 토크나이저를 생성 하였습니다. 질문 데이터의 경우에는 토큰이 15개 이하로 사용되고 대답 데이터의 경우에는 토큰이 18개 이하로 사용된 문장만을 추출 합니다. 또한 토크나이저의 단어사전 크기는 5,872개로 설정 하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-forty",
   "metadata": {},
   "source": [
    "#### 토크나이저 생성\n",
    "***\n",
    "+ 문장 길이 및 토큰 사용 빈도를 확인하기 위해, 토크나이저를 생성 합니다.\n",
    "\n",
    "\n",
    "+ 인코더 입력 문장과 디코더 입력 문장 모두 한국어 이므로 동일한 토크나이저를 공유 합니다.\n",
    "\n",
    "\n",
    "+ 총 6,810개의 토큰을 획득 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corrected-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Vocab Size: 6,810\n"
     ]
    }
   ],
   "source": [
    "def get_tokenizer(corpus, vocab_size):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        filters='',\n",
    "        oov_token=\"<UNK>\",\n",
    "        num_words=vocab_size\n",
    "    )\n",
    "    corpus_input = [sentence.split() for sentence in corpus]\n",
    "    tokenizer.fit_on_texts(corpus_input)\n",
    "    \n",
    "    if vocab_size is not None:\n",
    "        words_frequency = [w for w,c in tokenizer.word_index.items() if c >= vocab_size + 1]\n",
    "        for w in words_frequency:\n",
    "            del tokenizer.word_index[w]\n",
    "            del tokenizer.word_counts[w]\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "concat = pd.concat([dataset[\"Q\"], dataset[\"A\"]])\n",
    "tokenizer = get_tokenizer(concat, None)\n",
    "\n",
    "print(\"Tokenizer Vocab Size:\", f\"{len(tokenizer.word_index):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-grill",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 정수화\n",
    "***\n",
    "+ 앞서 생성한 토크나이저를 바탕으로 자연어 데이터를 정수 형테로 변환 하여 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adaptive-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_sentence(copus, tokenizer):\n",
    "    tensor = tokenizer.texts_to_sequences(copus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tensor, padding='post'\n",
    "    )\n",
    "    return tensor\n",
    "\n",
    "\n",
    "enc_tensor = encoding_sentence(dataset[\"Q\"], tokenizer)\n",
    "dec_tensor = encoding_sentence(dataset[\"A\"], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-universal",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 빈도 시각화 및 출력 함수 생성\n",
    "***\n",
    "+ 데이터 빈도 시각화 및 출력하는 함수를 생성 합니다.\n",
    "\n",
    "\n",
    "+ 문장의 길이와 단어 사용 빈도를 확인하기 위해 사용 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strange-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 빈도 시각화 함수=========================\n",
    "def show_sentence_length(sentence_num, title, range_=[0, 500]):\n",
    "    plt.figure(figsize=(13, 5))\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(sentence_num, bins=range_[1], range=range_, facecolor='b', label='train')\n",
    "    plt.xlabel('Number of question')\n",
    "    plt.ylabel('Count of question')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(sentence_num, labels=['token counts'], showmeans=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"< Sentence Info >\".center(100, \"=\"))\n",
    "    print(f\"길이 최대:    {np.max(sentence_num):4d}\")\n",
    "    print(f\"길이 최소:    {np.min(sentence_num):4d}\")\n",
    "    print(f\"길이 평균:    {np.mean(sentence_num):7.3f}\")\n",
    "    print(f\"길이 표준편차: {np.std(sentence_num):7.3f}\", end=\"\\n\\n\")\n",
    "    \n",
    "    percentile25 = np.percentile(sentence_num, 25)\n",
    "    percentile50 = np.percentile(sentence_num, 50)\n",
    "    percentile75 = np.percentile(sentence_num, 75)\n",
    "    percentileIQR = percentile75 - percentile25\n",
    "    percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "    \n",
    "    print(f\" 25/100분위:  {percentile25:7.3f}\")\n",
    "    print(f\" 50/100분위:  {percentile50:7.3f}\")\n",
    "    print(f\" 75/100분위:  {percentile75:7.3f}\")\n",
    "    print(f\" MAX/100분위: {percentileMAX:7.3f}\")\n",
    "    print(f\" IQR: {percentileIQR:7.3f}\")\n",
    "    print(\"=\" * 100)\n",
    "#End==========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-vector",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 문장 길이 확인\n",
    "***\n",
    "+ 질문(Question) 데이터의 경우, 문장이 평균 약 7개의 토큰으로 이루어져 있으며, 4분위의 경우 약 15개의 토큰으로 이루어져 있습니다.\n",
    "\n",
    "\n",
    "+ 대답(Answer) 데이터의 경우, 문장이 평균 약 10개의 토큰으로 이루어져 있으며, 4분위의 경우 약 18개의 토큰으로 이루어져 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tutorial-celtic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================< Sentence Info >==========================================\n",
      "길이 최대:      32\n",
      "길이 최소:       1\n",
      "길이 평균:      7.035\n",
      "길이 표준편차:   3.524\n",
      "\n",
      " 25/100분위:    5.000\n",
      " 50/100분위:    6.000\n",
      " 75/100분위:    9.000\n",
      " MAX/100분위:  15.000\n",
      " IQR:   4.000\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================< Sentence Info >==========================================\n",
      "길이 최대:      42\n",
      "길이 최소:       3\n",
      "길이 평균:     10.377\n",
      "길이 표준편차:   3.575\n",
      "\n",
      " 25/100분위:    8.000\n",
      " 50/100분위:   10.000\n",
      " 75/100분위:   12.000\n",
      " MAX/100분위:  18.000\n",
      " IQR:   4.000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_sentence_len(tensor):\n",
    "    counts = []\n",
    "    for sentence in tensor.tolist():\n",
    "        try:\n",
    "            idx = sentence.index(0)\n",
    "            counts.append(idx)\n",
    "        except:\n",
    "            counts.append(len(sentence))\n",
    "    return counts\n",
    "\n",
    "\n",
    "enc_counts = get_sentence_len(enc_tensor)\n",
    "dec_counts = get_sentence_len(dec_tensor)\n",
    "\n",
    "show_sentence_length(enc_counts, \"<Fig 1> Question Sentence Infomation\", [0, 20])\n",
    "show_sentence_length(dec_counts, \"<Fig 2> Answer Sentence Infomation\", [0, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-geneva",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 토큰별 사용 빈도 확인\n",
    "***\n",
    "+ 추후 단어사전 크기를 설정하기 위해, 토큰별 사용 빈도를 확인 합니다.\n",
    "\n",
    "\n",
    "+ 평균 약 30회 사용 되었고 4분위의 토큰은 약 16회 사용 되었습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dominican-capital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================< Sentence Info >==========================================\n",
      "길이 최대:    13870\n",
      "길이 최소:       1\n",
      "길이 평균:     30.048\n",
      "길이 표준편차: 310.114\n",
      "\n",
      " 25/100분위:    1.000\n",
      " 50/100분위:    2.000\n",
      " 75/100분위:    7.000\n",
      " MAX/100분위:  16.000\n",
      " IQR:   6.000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "freq = [value for value in tokenizer.word_counts.values()]\n",
    "\n",
    "show_sentence_length(freq, \"<Fig 3> Word Frequency\", [0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-journalism",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 사용 빈도 4분위에 해당하는 토큰 개수 확인\n",
    "***\n",
    "+ 사용 빈도 4분위에 해당하는 토큰의 수는 총 5,872개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ancient-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Used Under 16: 5,872\n"
     ]
    }
   ],
   "source": [
    "def wordNumByFreq(tokenizer, freq_num):\n",
    "    sorted_freq = sorted(tokenizer.word_counts.items(), key=lambda x: x[1])\n",
    "    for idx, (_, freq) in enumerate(sorted_freq):\n",
    "        if freq > freq_num: break;\n",
    "    return idx\n",
    "\n",
    "\n",
    "print(f\"Words Used Under {16}: {wordNumByFreq(tokenizer, 16):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-dining",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 최종 토크나이저 생성\n",
    "***\n",
    "+ 사용 빈도 4분위에 해당하는 토큰의 수는 총 5,872개 입니다.\n",
    "\n",
    "\n",
    "+ 또한, 질문(Question) 문장의 길이가 15 이하이고 대답(Answer) 문장의 길이가 18 이하인 문장만 추출 합니다.\n",
    "\n",
    "\n",
    "+ 문장 정수 인코딩은 데이터 증강 후 수행 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlimited-facility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Vocab Size: 5,872\n"
     ]
    }
   ],
   "source": [
    "#토크나이저 생성===============\n",
    "concat = pd.concat([dataset[\"Q\"], dataset[\"A\"]])\n",
    "tokenizer = get_tokenizer(concat, 5872)\n",
    "#End===========================\n",
    "\n",
    "\n",
    "#문장 길이 정제================\n",
    "q = dataset[\"Q\"].apply(lambda x: len(tokenizer.texts_to_sequences([x])[0]) <= 15)\n",
    "a = dataset[\"A\"].apply(lambda x: len(tokenizer.texts_to_sequences([x])[0]) <= 18)\n",
    "dataset = dataset[q & a]\n",
    "#End===========================\n",
    "\n",
    "\n",
    "print(\"Tokenizer Vocab Size:\", f\"{len(tokenizer.word_index):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-empty",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 테스트 데이터 분할\n",
    "***\n",
    "+ 모델 검증 단계에서 사용할 100개의 테스트 데이터를 분할 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "foster-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>같이 놀 러 갈 친구 가 없 어</td>\n",
       "      <td>&lt;sos&gt; 혼자 도 좋 아요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>개념 도 놓 고 옴</td>\n",
       "      <td>&lt;sos&gt; 그게 제일 중요 한 건데요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>강아지 키우 고 싶 어</td>\n",
       "      <td>&lt;sos&gt; 책임 질 수 있 을 때 키워 보 세요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>같이 할 수 있 는 취미 생활 뭐 있 을까</td>\n",
       "      <td>&lt;sos&gt; 함께 하 면 서로 를 더 많이 알 게 될 거 예요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>개념 이 없 어</td>\n",
       "      <td>&lt;sos&gt; 그게 제일 중요 한 건데요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Q                                          A\n",
       "74        같이 놀 러 갈 친구 가 없 어                    <sos> 혼자 도 좋 아요 . <eos>\n",
       "87               개념 도 놓 고 옴               <sos> 그게 제일 중요 한 건데요 . <eos>\n",
       "68             강아지 키우 고 싶 어         <sos> 책임 질 수 있 을 때 키워 보 세요 . <eos>\n",
       "79  같이 할 수 있 는 취미 생활 뭐 있 을까  <sos> 함께 하 면 서로 를 더 많이 알 게 될 거 예요 . <eos>\n",
       "88                 개념 이 없 어               <sos> 그게 제일 중요 한 건데요 . <eos>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = dataset[:100]\n",
    "dataset = dataset[100:]\n",
    "\n",
    "display(test_dataset.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-sandwich",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. 데이터 증강\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 전처리를 통해 총 11,750개의 데이터를 확보하였습니다. 이는 학습하기 부족한 수로, 데이터 증강을 통해 데이터를 늘립니다. 데이터 증강 방법은 데이터 문장으로부터 무작위로 단어를 선택 합니다. 이미 학습된 Word2Vec을 이용하여 선택한 단어와 비슷한 단어를 추출 합니다. 즉, 임베딩 간 거리가 가까운 단어를 추출하는 것입니다. 선택한 단어를, 추출한 비슷한 단어로 대체 합니다. 해당 문장을 학습 데이터로 사용 합니다. 이러한 방법을 사용하여 질문 데이터와 대답 데이터를 각각 증강 합니다. 최종 29,951개의 학습 데이터를 확보 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-mitchell",
   "metadata": {},
   "source": [
    "#### 한국어 Word2Vec 불러오기\n",
    "***\n",
    "+ 한국어로 사전 훈련된 Embedding 모델을 불러옵니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "funded-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec.load('./dataset/ko.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-therapy",
   "metadata": {},
   "source": [
    "#### 학습 데이터 출처\n",
    "***\n",
    "+ Kyubyong Park, Pre-trained word vectors of 30+ languages(2016), https://github.com/Kyubyong/wordvectors\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-badge",
   "metadata": {},
   "source": [
    "#### _'bin' File Load Error_\n",
    "***\n",
    "+ gensim의 버전으로 인하여 `ko.bin` 파일을 읽을 수 없는 이슈가 존재합니다. 이러한 경우 아래의 코드를 통해 버전을 낮추어 재설치 합니다.\n",
    "\n",
    "> `$ pip install --upgrade gensim==3.8.3`\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-dakota",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 증강 함수 생성\n",
    "***\n",
    "+ `lexical_sub` 함수는 문장을 입력하면 무작위로 선택한 단어를 wrod2vec에 기반하여 비슷한 단어로 대체하여 문장을 반환 합니다.\n",
    "\n",
    "\n",
    "+ `argument_data` 함수는 `Question`과 `Answer` 데이터에 맞추어 데이터 증강을 실시 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "twelve-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexical Substitution=================================\n",
    "def lexical_sub(sentence, word2vec, enc_arg=True):\n",
    "    toks = sentence.split()\n",
    "    if not enc_arg:   #<sos>, <eos> 토큰 제외\n",
    "        toks = toks[1:-1]\n",
    "\n",
    "    _from = random.choice(toks)\n",
    "    \n",
    "    try:\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "    except:\n",
    "        return \"_\"\n",
    "    \n",
    "    res = \"\"\n",
    "    for tok in sentence.split():\n",
    "        if tok == _from:\n",
    "            res += _to + \" \"\n",
    "        else:\n",
    "            res += tok + \" \"\n",
    "    return res\n",
    "#End==================================================\n",
    "\n",
    "\n",
    "#Question, Answer에 따른 데이터 증강 함수=============\n",
    "def argument_data(dataset, word2vec, enc_arg=True):\n",
    "    qna = \"Q\" if enc_arg else \"A\"\n",
    "    arg = dataset[qna].apply(lambda x: lexical_sub(x, word2vec, enc_arg))\n",
    "    \n",
    "    arg_data = dataset.copy()\n",
    "    arg_data[qna] = arg\n",
    "    \n",
    "    arg_data = arg_data[arg_data[qna] != \"_\"]\n",
    "    return arg_data\n",
    "#End=================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-appearance",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 증강 수행\n",
    "***\n",
    "+ 앞서 정의한 함수를 사용하여 `Quenstion`과 `Answer` 데이터별로 데이터 증강을 수행 합니다.\n",
    "\n",
    "\n",
    "+ `걱정 좀 없이 살고 싶다.` 문장을 바탕으로 `걱정 조금 없이 살고 싶다.`의 문장을 생성 한 것을 확인할 수 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "australian-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Sentence: 걱정 좀 없이 살 고 싶 다 . ======> 걱정 조금 없이 살 고 싶 다 . \n",
      "Answer Sentence: <sos> 누구 나 걱정 은 있 어요 . <eos> ======> <sos> 누구 나 걱정 은 있 는데요 . <eos> \n"
     ]
    }
   ],
   "source": [
    "#데이터 증강==========================================\n",
    "enc_alpha = argument_data(dataset, w2v, True)\n",
    "dec_alpha = argument_data(dataset, w2v, False)\n",
    "#End==================================================\n",
    "\n",
    "\n",
    "#데이터 증강 출력=====================================\n",
    "enc_idx = set(dataset.index)\n",
    "enc_alpha_idx = set(enc_alpha.index)\n",
    "dec_alpha_idx = set(dec_alpha.index)\n",
    "\n",
    "vet = enc_idx & enc_alpha_idx & dec_alpha_idx\n",
    "vet = list(vet)[0]\n",
    "\n",
    "print(f\"Question Sentence: {dataset['Q'][vet]} ======> {enc_alpha['Q'][vet]}\")\n",
    "print(f\"Answer Sentence: {dataset['A'][vet]} ======> {dec_alpha['A'][vet]}\")\n",
    "#End=================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-force",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 기존 데이터와 증강 데이터 합치기\n",
    "***\n",
    "+ 기존 11,750개의 데이터로부터 데이터 증강을 수행하여 최종 29,951개의 데이터를 획득 합니다.\n",
    "\n",
    "\n",
    "+ 또한 모델의 올바른 학습을 위하여 데이터를 무작위로 섞어 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "necessary-applicant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Num: 29,951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>내일 대관식 이 야</td>\n",
       "      <td>&lt;sos&gt; 떨리 겠 어요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>내 사랑 은 어디 있 나</td>\n",
       "      <td>&lt;sos&gt; 같 은 하늘 아래 묻히 에 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>산 뛰어넘 어 산 이 네</td>\n",
       "      <td>&lt;sos&gt; 그래도 넘 을 수 있 을 거 예요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>오늘 도 보 고 왔 어서</td>\n",
       "      <td>&lt;sos&gt; 그것 이 최선 의 선택 일거 라 생각 해요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>건강 관리</td>\n",
       "      <td>&lt;sos&gt; 운동 을 해의 보 세요 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Q                                      A\n",
       "9539     내일 대관식 이 야                   <sos> 떨리 겠 어요 . <eos>\n",
       "882    내 사랑 은 어디 있 나          <sos> 같 은 하늘 아래 묻히 에 . <eos> \n",
       "2311  산 뛰어넘 어 산 이 네        <sos> 그래도 넘 을 수 있 을 거 예요 . <eos>\n",
       "7158  오늘 도 보 고 왔 어서   <sos> 그것 이 최선 의 선택 일거 라 생각 해요 . <eos>\n",
       "107            건강 관리            <sos> 운동 을 해의 보 세요 . <eos> "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.concat([dataset, enc_alpha, dec_alpha])\n",
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "print(f\"Dataset Num: {len(dataset):,}\")\n",
    "display(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-healing",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 정수 인코딩 수행\n",
    "***\n",
    "+ 최종적으로 문장의 정수 인코딩을 수행하여 줍니다.\n",
    "\n",
    "\n",
    "+ 증강 데이터를 합하여 최종 29,951개의 학습 데이터를 얻습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "split-dialogue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data num: 29,951\n"
     ]
    }
   ],
   "source": [
    "enc_tensor = encoding_sentence(dataset[\"Q\"], tokenizer)\n",
    "dec_tensor = encoding_sentence(dataset[\"A\"], tokenizer)\n",
    "\n",
    "print(\"Data num:\", f\"{len(enc_tensor):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-webmaster",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. Transformer 모델 생성\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 트랜스포머 모델은 크게 인코더 부분과 디코더 부분으로 이루어져 있습니다. 모델의 목표는 'seq2seq'의 '시계열 데이터를 입력하여 시계열 데이터를 얻는 것'과 동일합니다. 기본적인 아이디어는 'Attention'만을 이용하여 'seq2seq'를 수행 하는 것입니다. 또한, 기존의 'Attention'은 RNN을 이용하여 데이터의 입력이 '순차적'으로 수행되었지만, 트랜스포머의 데이터 입력은 '동시에' 혹은 '병렬적'으로 수행된다는 특징이 있습니다. Transformer의 작동 방식과 각 레이어의 역할에 대한 설명은 'aiffel_exploration' 저장소((Repository)의 <a href=\"https://nbviewer.org/github/YAGI0423/aiffel_exploration/blob/master/exploration_15/EX15_v3_1.ipynb\">[Exploration 15]</a>에서 자세히 다루고 있습니다. 인코더와 디코더 레이어는 2층을 쌓았으며, 학습 데이터 수가 적기 때문에 벡터 사이즈와 피드포워드 레이어의 유닛 수를 128로 설정 하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-consistency",
   "metadata": {},
   "source": [
    "#### Positional 인코딩 레이어 및 멀티 헤드 어텐션 레이어 함수 정의\n",
    "***\n",
    "+ Positional 인코딩 레이어 및 멀티 헤드 어텐션 레이어 함수를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "introductory-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positional Encoding==================================================\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i)/d_model)\n",
    "    \n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "    \n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    \n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table\n",
    "#End==================================================================\n",
    "\n",
    "\n",
    "#MultiHeadAttention====================================================\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "            \n",
    "        self.depth = d_model // self.num_heads\n",
    "            \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "            \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "            \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "        \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask\n",
    "        )\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "                \n",
    "        return out, attention_weights\n",
    "#End==================================================================\n",
    "\n",
    "    \n",
    "#Position-wise Feed-Forward Network===================================\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n",
    "#End==================================================================\n",
    "\n",
    "\n",
    "#Mask 레이어==========================================================\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "#End=================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-expense",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 인코더 레이어 및 디코더 레이어 함수 정의\n",
    "***\n",
    "+ 인코더 레이어 및 디코더 레이어 함수를 정의 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wooden-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder 레이어=======================================================\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "#End==================================================================\n",
    "\n",
    "\n",
    "#Decoder 레이어=======================================================\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "       \n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "#End=================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-squad",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 인코더 및 디코더 함수 정의\n",
    "***\n",
    "+ 인코더 및 디코더 함수를 정의 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comic-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder==============================================================\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "#End==================================================================\n",
    "\n",
    "\n",
    "#Decoder==============================================================\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "#End=================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-infection",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 트랜스포머 함수 정의\n",
    "***\n",
    "+ 트랜스포머 생성 함수를 정의합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beautiful-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers, d_model, n_heads, d_ff,\n",
    "        src_vocab_size, tgt_vocab_size,\n",
    "        pos_len,\n",
    "        dropout=0.2,\n",
    "        shared=True\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "            \n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-termination",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 생성\n",
    "***\n",
    "+ 인코더와 디코더는 동일한 토크나이저를 공유하고 있으므로 모두 5,872개로 설정 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cross-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=128,\n",
    "    n_heads=8,\n",
    "    d_ff=128,\n",
    "    dropout=0.5,\n",
    "    pos_len=200,\n",
    "    shared=True,\n",
    "    src_vocab_size=5872, tgt_vocab_size=5872\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-meeting",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 7. 모델 학습\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 학습 옵티마이저는 Adam을 사용하며 배치 사이즈는 64로 설정하고 총 10회 학습 합니다. 최종 손실값은 0.740 입니다. 「지루하다, 놀러가고 싶어.」, 「오늘 일찍 일어났더니 피곤하다.」 등의 총 4개의 문장을 입력한 결과, 「시간이 필요한가 봐요.」, 「아침 일이 많았나 봅니다.」 등의 문장을 출력하였습니다. [표 1]은 입력 문장과 그에 대한 모델의 출력 문장을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "|Index|Question|Answer|\n",
    "|:--------:|:--------:|:--------:|\n",
    "|1|지루하다, 놀러가고 싶어.|시간이 필요한가봐요.|\n",
    "|2|오늘 일찍 일어났더니 피곤하다.|아침 일이 많았나 봅니다 .|\n",
    "|3|간만에 여자친구랑 데이트 하기로 했어.|좋은 친구가 여기가 여기 가길 바랄게요.|\n",
    "|4|집에 있는다는 소리야.|익숙 &lt;UNK>을 &lt;UNK> 군요.|\n",
    "\n",
    "[표 1] Transformer 모델의 생성 문장\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-discovery",
   "metadata": {},
   "source": [
    "#### 학습 옵티마이저 설정\n",
    "***\n",
    "+ 학습률의 경우 고정된 값을 이용하지 않고 LearningRateScheduler를 이용하여, 높은 학습률로부터 점차 낮추는 방식을 사용 합니다.\n",
    "\n",
    "\n",
    "+ 옵티마이저는 Adam을 이용합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "union-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LearningRateScheduler=====================\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "#End=======================================\n",
    "\n",
    "\n",
    "#손실 함수=================================  \n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)    \n",
    "#End=======================================\n",
    "\n",
    "    \n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-detective",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 학습 함수 정의\n",
    "***\n",
    "+ 'GradientTape'를 이용하여 학습 함수를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fresh-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수======================================\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns\n",
    "#End==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-river",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 학습\n",
    "***\n",
    "+ 앞서 생성한 모델을 학습 합니다.\n",
    "\n",
    "\n",
    "+ 배치 사이즈는 64, 학습 회수는 10회로 설정 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "treated-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc792caaf584f638ea2286a4c7d3d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df09fa10320b4c4ba904ca4c8e8359ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcfd946346142f6ab0c918adaf8a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22399e7264e743a8b9459f0784461b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333f3dbd0eb64f3e947a6512a063e74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3320813624874f4facc24ef0a9f4ed25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c34a3d606346cea1fab0731098d434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c396961951544bf4b93f2d80d24286ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8016e57776845afb96d2340a973153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ee1892c6844399a4d001bc9a58fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_fit(enc_train, dec_train, model, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        idx_list = list(range(0, enc_train.shape[0], batch_size))\n",
    "        random.shuffle(idx_list)\n",
    "        t = tqdm(idx_list)\n",
    "\n",
    "        for (batch, idx) in enumerate(t):\n",
    "            batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "            train_step(\n",
    "                enc_train[idx:idx+batch_size],\n",
    "                dec_train[idx:idx+batch_size],\n",
    "                model,\n",
    "                optimizer\n",
    "            )\n",
    "\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "            t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "            \n",
    "\n",
    "model_fit(enc_tensor, dec_tensor, transformer, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-breeding",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 예문 생성\n",
    "***\n",
    "+ `지루하다, 놀러가고 싶어.`, `오늘 일찍 일어났더니 피곤하다.` 등의 총 4개의 문장을 모델에 입력하여 생성 문장을 확인 합니다.\n",
    "\n",
    "\n",
    "+ 그 결과, `시간이 필요한가봐요.`, `아침 일이 많았나 봅니다.` 등의 예문을 출력하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "similar-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Quenstion: 지루하다, 놀러가고 싶어.                \tAnswer: 시간 이 필요 한가 봐요 .               \n",
      "Quenstion: 오늘 일찍 일어났더니 피곤하다.             \tAnswer: 아침 일 이 많 았 나 봅니다 .            \n",
      "Quenstion: 간만에 여자친구랑 데이트 하기로 했어.         \tAnswer: 좋 은 친구 가 여기 가 여기 가 길 바랄게요 .   \n",
      "Quenstion: 집에 있는다는 소리야.                  \tAnswer: 익숙 <UNK> 을 <UNK> 군요 .         \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def translate(sentence, model, tokenizer, enc_tensor, dec_tensor):\n",
    "    enc_maxlen = enc_tensor.shape[-1]\n",
    "    dec_maxlen = dec_tensor.shape[-1]\n",
    "\n",
    "    sos_idx = tokenizer.word_index['<sos>']\n",
    "    eos_idx = tokenizer.word_index['<eos>']\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    m = Mecab()\n",
    "    sentence = m.morphs(sentence)\n",
    "\n",
    "    _input = tokenizer.texts_to_sequences([sentence])\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        _input,\n",
    "        maxlen=enc_maxlen,\n",
    "        padding='post'\n",
    "    )\n",
    "\n",
    "    ids = []\n",
    "    output = tf.expand_dims([sos_idx], 0)\n",
    "\n",
    "    for i in range(dec_maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(\n",
    "            _input, output\n",
    "        )\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(\n",
    "            _input, output, enc_padding_mask, combined_mask, dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predicted_id = tf.argmax(\n",
    "            tf.math.softmax(predictions, axis=-1)[0, -1]\n",
    "        ).numpy().item()\n",
    "\n",
    "        if predicted_id == eos_idx:\n",
    "            result = tokenizer.sequences_to_texts([ids])\n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "    result = tokenizer.sequences_to_texts([ids])\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"=\" * 100)\n",
    "test_sentences = [\n",
    "    \"지루하다, 놀러가고 싶어.\",\n",
    "    \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "    \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "    \"집에 있는다는 소리야.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    ans = translate(sentence, transformer, tokenizer, enc_tensor, dec_tensor)[0]\n",
    "    print(f\"Quenstion: {sentence:<30}\\tAnswer: {ans:<30}\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-toilet",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 8. 모델 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; BLEU를 이용하여 100개의 테스트 데이터를 평가 합니다. BLEU는 0에서 1사이의 값을 가지며, 값이 높을 수록 좋은 문장에 해당 합니다. [표 2]는 BLEU 점수 척도를 제시한 것 입니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 예제에서는 Beam search를 이용하여 좀 더 정확한 평가를 도모 합니다. 테스트 데이터 100개에 대한 BLEU는 0.419로, [표 2]를 바탕으로 해석하였을 때, 이는 모델의 대답(Answer)이 양호한 수준이라 할 수 있습니다. \n",
    "</span><br><br>\n",
    "\n",
    "|BLEU score|Answer|\n",
    "|:--------:|:--------:|\n",
    "|10점 미만|거의 의미 없음|\n",
    "|10 ~ 19점|핵심을 파악하기 어려움|\n",
    "|20 ~ 29점|요점은 명확하지만 많은 문법적 오류가 있음|\n",
    "|30 ~ 39점|이해할 수 있는 양호한 번역|\n",
    "|40 ~ 49점|고품질 번역|\n",
    "|50 ~ 60점|매우 우수한 품질의 적절하고 유창한 번역|\n",
    "|60점 초과|대체적으로 사람보다 우수한 품질|\n",
    "\n",
    "[표 2] BLEU 점수 척도(https://cloud.google.com/translate/automl/docs/evaluate?hl=ko#bleu)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-occasions",
   "metadata": {},
   "source": [
    "#### Beam Search 및 BLEU 계산 함수 정의\n",
    "***\n",
    "+ Beam Search 문장 획득 함수와 BLEU를 구하기 위한 함수를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gentle-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 입력 및 출력 함수======================\n",
    "def calc_prob(src_ids, tgt_ids, model):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(\n",
    "        src_ids, tgt_ids\n",
    "    )\n",
    "    \n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns = model(\n",
    "        src_ids, tgt_ids, enc_padding_mask, combined_mask, dec_padding_mask\n",
    "    )\n",
    "    return tf.math.softmax(predictions, axis=-1)\n",
    "#End=========================================\n",
    "\n",
    "\n",
    "#Beam search=================================\n",
    "def beam_search_decoder(\n",
    "    sentence, model, tokenizer,\n",
    "    enc_maxlen, dec_maxlen,\n",
    "    beam_size\n",
    "):\n",
    "    sos_idx = tokenizer.word_index['<sos>']\n",
    "    eos_idx = tokenizer.word_index['<eos>']\n",
    "\n",
    "    tokens = tokenizer.texts_to_sequences([sentence])\n",
    "    src_in = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokens,\n",
    "        maxlen=enc_maxlen,\n",
    "        padding='post'\n",
    "    )\n",
    "\n",
    "    pred_cache = np.zeros((beam_size * beam_size, dec_maxlen), dtype=np.long)\n",
    "    pred = np.zeros((beam_size, dec_maxlen), dtype=np.long)\n",
    "\n",
    "    eos_flag = np.zeros((beam_size, ), dtype=np.long)\n",
    "    scores = np.ones((beam_size, ))\n",
    "\n",
    "    pred[:, 0] = sos_idx\n",
    "\n",
    "    dec_in = tf.expand_dims(pred[0, :1], 0)\n",
    "    prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "    \n",
    "    \n",
    "    for seq_pos in range(1, dec_maxlen):\n",
    "        score_cache = np.ones((beam_size * beam_size, ))\n",
    "\n",
    "        # init\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            score_cache[cache_pos:cache_pos+beam_size] = scores[branch_idx]\n",
    "            pred_cache[cache_pos:cache_pos+beam_size, :seq_pos] = \\\n",
    "            pred[branch_idx, :seq_pos]\n",
    "\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            if seq_pos != 1:   # 모든 Branch를 로 시작하는 경우를 방지\n",
    "                dec_in = pred_cache[branch_idx, :seq_pos]\n",
    "                dec_in = tf.expand_dims(dec_in, 0)\n",
    "\n",
    "                prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "\n",
    "            for beam_idx in range(beam_size):\n",
    "                max_idx = np.argmax(prob)\n",
    "\n",
    "                score_cache[cache_pos+beam_idx] *= prob[max_idx]\n",
    "                pred_cache[cache_pos+beam_idx, seq_pos] = max_idx\n",
    "\n",
    "                prob[max_idx] = -1\n",
    "\n",
    "        for beam_idx in range(beam_size):\n",
    "            if eos_flag[beam_idx] == -1: continue\n",
    "\n",
    "            max_idx = np.argmax(score_cache)\n",
    "            prediction = pred_cache[max_idx, :seq_pos+1]\n",
    "\n",
    "            pred[beam_idx, :seq_pos+1] = prediction\n",
    "            scores[beam_idx] = score_cache[max_idx]\n",
    "            score_cache[max_idx] = -1\n",
    "\n",
    "            if prediction[-1] == eos_idx:\n",
    "                eos_flag[beam_idx] = -1\n",
    "    return pred\n",
    "#End=========================================\n",
    "\n",
    "\n",
    "#bleu 계산 함수==============================\n",
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu(\n",
    "        [reference],\n",
    "        candidate,\n",
    "        weights=weights,\n",
    "        smoothing_function=SmoothingFunction().method1\n",
    "    )\n",
    "#End=========================================\n",
    "\n",
    "\n",
    "#beam ssearch 및 bleu 계산 함수==============\n",
    "def beam_bleu(reference, ids, tokenizer, verbose=False):\n",
    "    reference = reference.split()\n",
    "\n",
    "    total_score = 0.0\n",
    "    for _id in ids:\n",
    "        seq2text = tokenizer.sequences_to_texts([_id])[0]\n",
    "        _idx =  seq2text.find(\"<eos>\")\n",
    "        seq2text = seq2text[6:_idx]\n",
    "        candidate = seq2text.split()\n",
    "        score = calculate_bleu(reference, candidate)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\" * 100)\n",
    "            print(\"Reference:\".ljust(10), \" \".join(reference))\n",
    "            print(\"Candidate:\".ljust(10), \" \".join(candidate), end=\"\\n\\n\")\n",
    "            print(\"BLEU:\".ljust(10), f\"{calculate_bleu(reference, candidate):.3f}\")\n",
    "            print(\"=\" * 100, end=\"\\n\\n\")\n",
    "        \n",
    "        total_score += score\n",
    "        \n",
    "    return total_score / len(ids)\n",
    "#End========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-aurora",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 예문의 Beam search 문장과 BLEU 출력하기\n",
    "***\n",
    "+ Reference에 해당하는 `땀을 식혀 주세요.` 문장과 모델이 출력한 5개의 Candidate 문장과 BLEU를 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "subtle-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Reference: 땀 을 식혀 주 세요 .\n",
      "Candidate: 잘 하 셨 어요 .\n",
      "\n",
      "BLEU:      0.044\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Reference: 땀 을 식혀 주 세요 .\n",
      "Candidate: 잘 하 셨 어요 는데\n",
      "\n",
      "BLEU:      0.000\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Reference: 땀 을 식혀 주 세요 .\n",
      "Candidate: 잘 하 셨 나 .\n",
      "\n",
      "BLEU:      0.044\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Reference: 땀 을 식혀 주 세요 .\n",
      "Candidate: 잘 <UNK> 셨 어요 .\n",
      "\n",
      "BLEU:      0.044\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Reference: 땀 을 식혀 주 세요 .\n",
      "Candidate: 잘 하 셨 나 는데\n",
      "\n",
      "BLEU:      0.000\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 15\n",
    "test_enc_sentence = test_dataset[\"Q\"][idx]\n",
    "\n",
    "test_dec_tensor = encoding_sentence(test_dataset[\"A\"], tokenizer)\n",
    "test_dec_sentence = tokenizer.sequences_to_texts([test_dec_tensor[idx]])[0]\n",
    "_idx = test_dec_sentence.find(\"<eos>\")\n",
    "test_dec_sentence = test_dec_sentence[6:_idx]\n",
    "\n",
    "\n",
    "ids = beam_search_decoder(\n",
    "    test_enc_sentence,\n",
    "    transformer, tokenizer,\n",
    "    enc_tensor.shape[-1], dec_tensor.shape[-1],\n",
    "    beam_size=5\n",
    ")\n",
    "\n",
    "bleu = beam_bleu(test_dec_sentence, ids, tokenizer, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-tunnel",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 테스트 데이터 BLEU 구하기\n",
    "***\n",
    "+ 앞서 정의한 함수를 이용하여 100개의 테스트 데이터의 BLEU를 구합니다.\n",
    "\n",
    "\n",
    "+ 최종 BLEU는 0.419로 매우 준수한 성능에 해당합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "psychological-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Test Data BLEU: 0.419\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "enc_maxlen = enc_tensor.shape[-1]\n",
    "dec_maxlen = dec_tensor.shape[-1]\n",
    "\n",
    "aver_bleu = 0\n",
    "for _, que, ans in test_dataset.itertuples():\n",
    "    ids = beam_search_decoder(\n",
    "        que,\n",
    "        transformer, tokenizer,\n",
    "        enc_maxlen, dec_maxlen,\n",
    "        beam_size=5\n",
    "    )\n",
    "    \n",
    "    test_dec_sentence = tokenizer.sequences_to_texts([que])[0]\n",
    "    _idx = test_dec_sentence.find(\"<eos>\")\n",
    "    test_dec_sentence = test_dec_sentence[6:_idx]\n",
    "    \n",
    "    aver_bleu += beam_bleu(test_dec_sentence, ids, tokenizer, verbose=False)\n",
    "    \n",
    "print(\"=\" * 100)\n",
    "print(f\"Test Data BLEU: {aver_bleu:.3f}\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-decline",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 9. 결론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Transformer 모델을 이용하여 한국어 챗봇 모델을 생성하고 이를 BLEU를 기준으로 삼아 평가하였습니다. 특히 정확한 평가를 위해 Beam search를 사용하여 Cadidate 문을 5개 생성하고 이를 BLEU로 평가하였습니다. 테스트 데이터는 학습 데이터 11,750개로부터 100개를 분할 한 것입니다. 이후 나머지 11,650개의 데이터를 이용하여 데이터 증강을 실시하여 최종 29,951개의 데이터를 학습 데이터로 이용하였습니다. \n",
    "</span><br><br>  \n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 테스트 데이터에 대한 모델의 BLEU score는 0.419입니다. 0.4의 경우 '이해할 수 있는 양호한 문장'에 해당하므로 모델의 성능이 준수하다고 평가할 수 있습니다. [표 3]은 Transformer 모델의 생성 문장을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "|Index|Question|Answer|\n",
    "|:--------:|:--------:|:--------:|\n",
    "|1|지루하다, 놀러가고 싶어.|시간이 필요한가봐요.|\n",
    "|2|오늘 일찍 일어났더니 피곤하다.|아침 일이 많았나 봅니다 .|\n",
    "|3|간만에 여자친구랑 데이트 하기로 했어.|좋은 친구가 여기가 여기 가길 바랄게요.|\n",
    "|4|집에 있는다는 소리야.|익숙 &lt;UNK>을 &lt;UNK> 군요.|\n",
    "\n",
    "[표 3] Transformer 모델의 생성 문장\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
